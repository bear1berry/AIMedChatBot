from __future__ import annotations

import asyncio
import logging
import os
import re
from dataclasses import dataclass, field
from typing import Dict, List, Optional

import httpx

from .modes import build_system_prompt, DEFAULT_MODE_KEY
from .limits import check_rate_limit

logger = logging.getLogger(__name__)

# --- AIMLAPI CONFIG ---------------------------------------------------------------------------

AIML_API_KEY = os.getenv("AIML_API_KEY", "").strip()
AIML_API_BASE = os.getenv("AIML_API_BASE", "https://api.aimlapi.com/v1").rstrip("/")

# –ë–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è)
AIML_MODEL_PRIMARY = os.getenv("AIML_MODEL_PRIMARY", "openai/gpt-4.1-2025-04-14")
AIML_MODEL_FAST = os.getenv("AIML_MODEL_FAST", "openai/gpt-4.1-mini-2025-04-14")
AIML_MODEL_REASONING = os.getenv(
    "AIML_MODEL_REASONING",
    "deepseek/deepseek-reasoner",
)
AIML_MODEL_GPT_OSS_120B = os.getenv(
    "AIML_MODEL_GPT_OSS_120B",
    "openai/gpt-oss-120b",
)
AIML_MODEL_DEEPSEEK_CHAT = os.getenv(
    "AIML_MODEL_DEEPSEEK_CHAT",
    "deepseek/deepseek-chat-v3.1",
)


class RateLimitError(Exception):
    """–û—à–∏–±–∫–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""

    def __init__(self, retry_after: Optional[int], message: Optional[str]) -> None:
        self.retry_after = retry_after
        self.message = message or "–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤."
        super().__init__(self.message)


@dataclass
class ConversationState:
    mode_key: str = DEFAULT_MODE_KEY
    messages: List[dict] = field(default_factory=list)
    # "auto" ‚Äì –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏; –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äì —Ä–µ–∂–∏–º—ã ¬´—á–∏—Å—Ç–æ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å¬ª
    model_profile: str = "auto"


_conversations: Dict[int, ConversationState] = {}


def get_state(user_id: int) -> ConversationState:
    state = _conversations.get(user_id)
    if state is None:
        state = ConversationState()
        _conversations[user_id] = state
    return state


def reset_state(user_id: int) -> None:
    state = get_state(user_id)
    state.messages.clear()


def set_mode(user_id: int, mode_key: str) -> ConversationState:
    state = get_state(user_id)
    state.mode_key = mode_key or DEFAULT_MODE_KEY
    state.messages.clear()
    return state


# --- –ü—Ä–æ—Ñ–∏–ª–∏ –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–∏ (—Ä–µ–∂–∏–º ¬´—á–∏—Å—Ç–æ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å¬ª) ----------------------------------------

_MODEL_PROFILE_LABELS: Dict[str, str] = {
    "auto": "–ê–≤—Ç–æ (–≤—ã–±–æ—Ä –ø–æ–¥ –∑–∞–¥–∞—á—É)",
    "gpt4.1": "GPT-4.1 (AIMLAPI)",
    "gpt4.1mini": "GPT-4.1 Mini (AIMLAPI)",
    "gpt_oss_120b": "GPT-OSS 120B (AIMLAPI)",
    "deepseek_reasoner": "DeepSeek Reasoner (AIMLAPI)",
    "deepseek_chat": "DeepSeek Chat (AIMLAPI)",
}


def set_model_profile(user_id: int, profile: str) -> ConversationState:
    """
    –†–µ–∂–∏–º—ã:
        - "auto"
        - "gpt4.1"
        - "gpt4.1mini"
        - "gpt_oss_120b"
        - "deepseek_reasoner"
        - "deepseek_chat"
    """
    if profile not in _MODEL_PROFILE_LABELS:
        profile = "auto"

    state = get_state(user_id)
    state.model_profile = profile
    # –ø—Ä–∏ —Å–º–µ–Ω–µ –º–æ–¥–µ–ª–∏ ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º –¥–∏–∞–ª–æ–≥ —Å —á–∏—Å—Ç–æ–≥–æ –ª–∏—Å—Ç–∞
    state.messages.clear()
    return state


def get_model_profile_label(profile: str) -> str:
    return _MODEL_PROFILE_LABELS.get(profile, _MODEL_PROFILE_LABELS["auto"])


# --- –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø–æ–¥ Telegram (HTML) ---------------------------------------------


def _postprocess_reply(text: str) -> str:
    """
    –õ—ë–≥–∫–∞—è —á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –ø–æ–¥ Telegram (HTML parse_mode):

    - —É–±–∏—Ä–∞–µ–º ```code fences```;
    - –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º markdown-–∑–∞–≥–æ–ª–æ–≤–∫–∏ ##, ### –≤ <b>...</b>;
    - —É–±–∏—Ä–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Ç–∞–±–ª–∏—Ü —Ç–∏–ø–∞ |----|----|;
    - —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü '| –∫–æ–ª1 | –∫–æ–ª2 |' –ø—Ä–µ–≤—Ä–∞—â–∞–µ–º –≤ –±—É–ª–ª–µ—Ç—ã;
    - —Å—Ö–ª–æ–ø—ã–≤–∞–µ–º >2 –ø–æ–¥—Ä—è–¥ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏.
    """
    if not text:
        return text

    # 1) —É–±—Ä–∞—Ç—å ```code fences``` —Ü–µ–ª–∏–∫–æ–º
    text = re.sub(r"```.+?```", "", text, flags=re.S)

    # 2) –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤–∏–¥–∞ "## –ó–∞–≥–æ–ª–æ–≤–æ–∫" -> –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ + <b>–ó–∞–≥–æ–ª–æ–≤–æ–∫</b>
    def _heading_repl(match: re.Match) -> str:
        title = match.group(1).strip()
        if not title:
            return ""
        return f"\n<b>{title}</b>\n"

    text = re.sub(r"^\s*#{2,6}\s+(.+)$", _heading_repl, text, flags=re.M)

    # 3) —Å—Ç—Ä–æ–∫–∏-—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ markdown-—Ç–∞–±–ª–∏—Ü —Ç–∏–ø–∞ |----|----|
    text = re.sub(
        r"^\s*\|?\s*-{2,}\s*(\|-*)?\s*$",
        "",
        text,
        flags=re.M,
    )

    # 4) —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü '| —è—á–µ–π–∫–∞1 | —è—á–µ–π–∫–∞2 |' -> –±—É–ª–ª–µ—Ç—ã
    def _table_line_repl(match: re.Match) -> str:
        row = match.group(0).strip()
        cells = [c.strip() for c in row.strip("|").split("|")]
        cells = [c for c in cells if c]
        if not cells:
            return ""
        head, *rest = cells
        tail = (" ‚Äî " + ", ".join(rest)) if rest else ""
        return f"‚Ä¢ <b>{head}</b>{tail}\n"

    text = re.sub(r"^\s*\|.*\|\s*$", _table_line_repl, text, flags=re.M)

    # 5) —É–±–∏—Ä–∞–µ–º —Ç—Ä–æ–π–Ω—ã–µ –∏ –±–æ–ª–µ–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    text = re.sub(r"\n{3,}", "\n\n", text)

    return text.strip()


# --- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –∏ –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π ------------------------------------------------------


def _classify_intent(text: str, mode_key: str) -> Optional[str]:
    """
    –ì—Ä—É–±–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞, —á—Ç–æ–±—ã –≤—ã–±–∏—Ä–∞—Ç—å –º–æ–¥–µ–ª—å/—à–∞–±–ª–æ–Ω.
    """
    t = text.lower()

    workout_markers = [
        "—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞",
        "—Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–π –ø–ª–∞–Ω",
        "–ø–ª–∞–Ω —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏",
        "–ø—Ä–æ–≥—Ä–∞–º–º—É —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫",
        "–ø—Ä–æ–≥—Ä–∞–º–º–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫",
        "—Å–ø–ª–∏—Ç",
        "upper lower",
        "–≤–µ—Ä—Ö/–Ω–∏–∑",
        "–∑–∞–ª",
        "—Å–ø–æ—Ä—Ç–∑–∞–ª",
        "—Ç—Ä–µ–Ω–∞–∂–µ—Ä–Ω—ã–π –∑–∞–ª",
        "—Ç—Ä–µ–Ω–∞–∂—ë—Ä–Ω—ã–π –∑–∞–ª",
    ]
    if any(m in t for m in workout_markers):
        return "workout"

    daily_plan_markers = [
        "–ø–ª–∞–Ω –Ω–∞ –¥–µ–Ω—å",
        "—Ä–∞—Å–ø–æ—Ä—è–¥–æ–∫ –¥–Ω—è",
        "—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –¥–µ–Ω—å",
        "—Ä–µ–∂–∏–º –¥–Ω—è",
        "—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–Ω—è",
        "–∫–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–µ–Ω—å",
        "to-do –Ω–∞ –¥–µ–Ω—å",
        "–ª–∏—Å—Ç –¥–µ–ª –Ω–∞ –¥–µ–Ω—å",
        "—Å–ø–∏—Å–æ–∫ –¥–µ–ª –Ω–∞ –¥–µ–Ω—å",
    ]
    if any(m in t for m in daily_plan_markers):
        return "daily_plan"

    checklist_markers = [
        "—á–µ–∫-–ª–∏—Å—Ç",
        "—á–µ–∫ –ª–∏—Å—Ç",
        "—á–µ–∫–ª–∏—Å—Ç",
        "—Å–ø–∏—Å–æ–∫ —à–∞–≥–æ–≤",
        "–ø–æ —à–∞–≥–∞–º",
        "–ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω",
        "–∞–ª–≥–æ—Ä–∏—Ç–º –¥–µ–π—Å—Ç–≤–∏–π",
        "—á—Ç–æ –¥–µ–ª–∞—Ç—å –ø–æ —à–∞–≥–∞–º",
        "–ø–æ—à–∞–≥–æ–≤–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è",
    ]
    if any(m in t for m in checklist_markers):
        return "checklist"

    content_markers = [
        "—Å–¥–µ–ª–∞–π –ø–æ—Å—Ç",
        "–ø–æ–¥–≥–æ—Ç–æ–≤—å –ø–æ—Å—Ç",
        "—Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç",
        "–ø–µ—Ä–µ–ø–∏—à–∏ —Ç–µ–∫—Å—Ç",
        "–ø–µ—Ä–µ–ø–∏—à–∏ —ç—Ç–æ",
        "–æ—Ñ–æ—Ä–º–∏ –ø–æ—Å—Ç",
        "–æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –∫–∞–Ω–∞–ª–∞",
        "–æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è",
        "–ø—Ä–∏–¥—É–º–∞–π –Ω–∞–∑–≤–∞–Ω–∏–µ",
        "–ø—Ä–∏–¥—É–º–∞–π –∑–∞–≥–æ–ª–æ–≤–æ–∫",
        "—Å–¥–µ–ª–∞–π –∑–∞–≥–æ–ª–æ–≤–æ–∫",
    ]
    if any(m in t for m in content_markers):
        return "content"

    return None


def _is_reasoning_task(text: str) -> bool:
    """
    –û—á–µ–Ω—å –≥—Ä—É–±–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á, –≥–¥–µ –ø–æ–ª–µ–∑–Ω–∞ reasoning-–º–æ–¥–µ–ª—å.
    """
    t = text.lower()
    reasoning_markers = [
        "—Ä–µ—à–∏ –∑–∞–¥–∞—á—É",
        "–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞",
        "–¥–æ–∫–∞–∂–∏",
        "–æ–±–æ—Å–Ω—É–π",
        "–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
        "step by step",
        "–ø–æ—à–∞–≥–æ–≤–æ",
        "–∫–µ–π—Å",
        "—Ä–∞–∑–±–æ—Ä —Å–ª—É—á–∞—è",
        "–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π",
        "–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π",
        "–Ω–∞–ø–∏—à–∏ –∫–æ–¥",
        "–æ—à–∏–±–∫–∞ –≤ –∫–æ–¥–µ",
    ]
    if any(m in t for m in reasoning_markers):
        return True

    # –¥–ª–∏–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å –º–Ω–æ–∂–µ—Å—Ç–≤–æ–º –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è ‚Äî —Ç–æ–∂–µ –∫–∞–Ω–¥–∏–¥–∞—Ç
    if len(t) > 600 and (t.count("?") + t.count(".") + t.count("!")) > 5:
        return True

    return False


def _select_models_for_query(text: str, state: ConversationState) -> List[str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ ID –º–æ–¥–µ–ª–µ–π AIMLAPI, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–æ–∏—Ç –∑–∞–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –ø—Ä–æ—Ñ–∏–ª—å (model_profile).
    """
    profile = state.model_profile

    # –†–µ–∂–∏–º—ã ¬´—á–∏—Å—Ç–æ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å¬ª
    if profile == "gpt4.1":
        return [AIML_MODEL_PRIMARY]
    if profile == "gpt4.1mini":
        return [AIML_MODEL_FAST]
    if profile == "gpt_oss_120b":
        return [AIML_MODEL_GPT_OSS_120B]
    if profile == "deepseek_reasoner":
        return [AIML_MODEL_REASONING]
    if profile == "deepseek_chat":
        return [AIML_MODEL_DEEPSEEK_CHAT]

    # –ê–≤—Ç–æ-—Ä–µ–∂–∏–º
    intent = _classify_intent(text, state.mode_key)
    reasoning = _is_reasoning_task(text)
    length = len(text)

    # –°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏ / –∫–æ–¥ ‚Äî reasoning + –æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç
    if reasoning:
        return [AIML_MODEL_REASONING, AIML_MODEL_PRIMARY]

    # –ü–ª–∞–Ω—ã, —á–µ–∫-–ª–∏—Å—Ç—ã
    if intent in {"workout", "daily_plan", "checklist"}:
        return [AIML_MODEL_PRIMARY]

    # –ö–æ—Ä–æ—Ç–∫–∏–µ –±—ã—Ç–æ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    if length < 120:
        return [AIML_MODEL_FAST]

    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ‚Äî –æ–¥–Ω–∞ –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
    return [AIML_MODEL_PRIMARY]


def _model_human_name(model_id: str) -> str:
    """
    –ö—Ä–∞—Å–∏–≤–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—ã–≤–æ–¥–∞ –≤ —á–∞—Ç.
    """
    mapping = {
        AIML_MODEL_PRIMARY: "GPT-4.1 (AIMLAPI)",
        AIML_MODEL_FAST: "GPT-4.1 Mini (AIMLAPI)",
        AIML_MODEL_REASONING: "DeepSeek Reasoner (AIMLAPI)",
        AIML_MODEL_GPT_OSS_120B: "GPT-OSS 120B (AIMLAPI)",
        AIML_MODEL_DEEPSEEK_CHAT: "DeepSeek Chat (AIMLAPI)",
        "deepseek/deepseek-r1": "DeepSeek Reasoner (AIMLAPI)",
        "deepseek/deepseek-chat": "DeepSeek Chat (AIMLAPI)",
        "openai/gpt-4.1-2025-04-14": "GPT-4.1 (AIMLAPI)",
        "openai/gpt-4.1-mini-2025-04-14": "GPT-4.1 Mini (AIMLAPI)",
        "openai/gpt-oss-120b": "GPT-OSS 120B (AIMLAPI)",
    }
    return mapping.get(model_id, model_id)


# --- –í—ã–∑–æ–≤ AIMLAPI ----------------------------------------------------------------------------


async def _call_model(model_name: str, messages: List[dict]) -> str:
    """
    –û–±—â–∏–π –≤—ã–∑–æ–≤ AIMLAPI /v1/chat/completions (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π).
    """
    if not AIML_API_KEY:
        raise RuntimeError("AIML_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

    url = f"{AIML_API_BASE}/chat/completions"
    payload = {
        "model": model_name,
        "messages": messages,
        "temperature": 0.7,
        "top_p": 1.0,
        "max_tokens": 2048,
    }
    headers = {
        "Authorization": f"Bearer {AIML_API_KEY}",
        "Content-Type": "application/json",
    }

    async with httpx.AsyncClient(timeout=60.0) as client:
        resp = await client.post(url, json=payload, headers=headers)
    resp.raise_for_status()
    data = resp.json()
    try:
        content = data["choices"][0]["message"]["content"]
    except (KeyError, IndexError, TypeError):
        raise RuntimeError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ AIMLAPI: {data!r}")
    return _postprocess_reply(content or "")


def _trim_history(state: ConversationState, max_turns: int = 12) -> None:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é, –æ—Å—Ç–∞–≤–ª—è—è –Ω–µ –±–æ–ª–µ–µ max_turns –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø–∞—Ä —Å–æ–æ–±—â–µ–Ω–∏–π user+assistant.
    """
    if len(state.messages) > max_turns * 2:
        state.messages = state.messages[-max_turns * 2 :]


# --- –ü—É–±–ª–∏—á–Ω—ã–π API –¥–ª—è —Ö–µ–Ω–¥–ª–µ—Ä–æ–≤ --------------------------------------------------------------


async def ask_ai(user_id: int, text: str, user_name: Optional[str] = None) -> str:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞: –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è -> –æ–¥–∏–Ω (–∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ) –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–¥–µ–ª–µ–π.
    """
    ok, retry_after, msg = check_rate_limit(user_id)
    if not ok:
        raise RateLimitError(retry_after=retry_after, message=msg)

    state = get_state(user_id)

    # –°–æ–±–∏—Ä–∞–µ–º system-–ø—Ä–æ–º–ø—Ç —Å —É—á—ë—Ç–æ–º —Ä–µ–∂–∏–º–∞
    system_prompt = build_system_prompt(mode_key=state.mode_key, user_name=user_name)

    # –û–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π: system + –∏—Å—Ç–æ—Ä–∏—è + –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    messages: List[dict] = [{"role": "system", "content": system_prompt}]
    messages.extend(state.messages)
    messages.append({"role": "user", "content": text})

    models = _select_models_for_query(text, state)

    try:
        if len(models) == 1:
            reply = await _call_model(models[0], messages)
        else:
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –≤—ã–∑–æ–≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π
            results = await asyncio.gather(
                *[_call_model(m, messages) for m in models],
                return_exceptions=True,
            )

            snippets: List[str] = []
            for idx, (model_name, result) in enumerate(zip(models, results)):
                if isinstance(result, Exception):
                    logger.exception("Error from model %s", model_name)
                    continue

                header_emoji = "ü§ñ" if idx == 0 else "üß†"
                qualifier = "–æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç" if idx == 0 else "–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∑–≥–ª—è–¥"
                header = f"{header_emoji} <b>{_model_human_name(model_name)} ‚Äî {qualifier}</b>"
                snippets.append(header + "\n\n" + str(result).strip())

            if not snippets:
                raise RuntimeError("–í—Å–µ –≤—ã–∑–æ–≤—ã –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –æ—à–∏–±–∫–æ–π.")

            separator = "\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n"
            reply = separator.join(snippets)

    except Exception:
        logger.exception("Error while calling AIMLAPI ChatCompletion")
        raise

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞
    state.messages.append({"role": "user", "content": text})
    state.messages.append({"role": "assistant", "content": reply})
    _trim_history(state)

    return reply


async def healthcheck_llm() -> bool:
    """
    –õ—ë–≥–∫–∏–π ping –º–æ–¥–µ–ª–∏ –ø–æ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
    """
    if not AIML_API_KEY:
        return False

    url = f"{AIML_API_BASE}/chat/completions"
    payload = {
        "model": AIML_MODEL_FAST or AIML_MODEL_PRIMARY,
        "messages": [{"role": "user", "content": "ping"}],
        "max_tokens": 1,
        "temperature": 0.0,
    }
    headers = {
        "Authorization": f"Bearer {AIML_API_KEY}",
        "Content-Type": "application/json",
    }

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.post(url, json=payload, headers=headers)
        resp.raise_for_status()
        return True
    except Exception:
        logger.exception("LLM healthcheck failed")
        return False
