import base64
import logging
import httpx
from .config import settings
from .modes import MODES, build_system_prompt
from .memory import get_history, save_message

# ------------------------------------------------------------
#  –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
# ------------------------------------------------------------
logger = logging.getLogger("bot.ai_client")
handler = logging.FileHandler("logs/ai.log", encoding="utf-8")
formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# ------------------------------------------------------------
#  –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π API endpoint Groq
# ------------------------------------------------------------
GROQ_URL = "https://api.groq.com/v1/chat/completions"

# ------------------------------------------------------------
#  –ú–æ–¥–µ–ª–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏
# ------------------------------------------------------------
PRIMARY_MODEL = "llama-3.1-70b-versatile"
FALLBACK_MODELS = [
    "llama-3.1-8b-instant",
    "mixtral-8x7b-32768",
    "gemma2-9b-it",
]


# ------------------------------------------------------------
#  –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –æ—Ç–ø—Ä–∞–≤—â–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤
# ------------------------------------------------------------
async def _send_request(payload):
    headers = {
        "Authorization": f"Bearer {settings.groq_api_key}",
        "Content-Type": "application/json"
    }

    async with httpx.AsyncClient(timeout=60) as client:
        resp = await client.post(GROQ_URL, json=payload, headers=headers)
        logger.info(f"Groq response code: {resp.status_code}")
        logger.debug(f"Groq response body: {resp.text}")

        resp.raise_for_status()
        return resp.json()


# ------------------------------------------------------------
#  –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Vision-–º–æ–¥–µ–ª—å Groq
# ------------------------------------------------------------
def _encode_image(image_bytes: bytes) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64."""
    return base64.b64encode(image_bytes).decode("utf-8")


async def ask_vision(prompt_text: str, image_bytes: bytes) -> str:
    """Vision —Ä–µ–∂–∏–º ‚Äî LLaMA3 Vision."""
    encoded = _encode_image(image_bytes)

    payload = {
        "model": "llama-3.2-90b-vision-preview",
        "messages": [
            {"role": "system", "content": "You are a medical vision analysis assistant."},
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": prompt_text},
                    {"type": "input_image", "image_url": f"data:image/jpeg;base64,{encoded}"}
                ],
            }
        ]
    }

    response = await _send_request(payload)
    return response["choices"][0]["message"]["content"]


# ------------------------------------------------------------
#  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—ç–º—É–ª—è—Ü–∏—è —á–µ—Ä–µ–∑ —Ç–µ–∫—Å—Ç)
#  Groq –Ω–µ –∏–º–µ–µ—Ç DALL¬∑E ‚Äî –¥–µ–ª–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä
# ------------------------------------------------------------
async def ask_image_generation(prompt: str) -> str:
    """–≠–º—É–ª—è—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∏ ‚Äî Groq –ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç DALL¬∑E.
       –ú—ã –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –¥–∞—ë–º —Å—Å—ã–ª–∫—É –¥–ª—è Midjourney/Flux."""
    
    payload = {
        "model": PRIMARY_MODEL,
        "messages": [
            {"role": "system", "content": "You are an AI that converts prompts into perfect image-generation prompts."},
            {"role": "user", "content": prompt}
        ]
    }

    response = await _send_request(payload)
    text = response["choices"][0]["message"]["content"]

    return f"üé® <b>–ì–æ—Ç–æ–≤–æ!</b>\n–í–æ—Ç –∏–¥–µ–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n\n<code>{text}</code>"


# ------------------------------------------------------------
#  –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–∏–∞–ª–æ–≥–∞
# ------------------------------------------------------------
async def ask_ai(user_id: int, mode: str, user_message: str) -> str:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—â–µ–Ω–∏—è —Å Groq.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–µ–∂–∏–º—ã, –∏—Å—Ç–æ—Ä–∏—é –∏ fallback.
    """

    logger.info(f"Sending request to Groq for user {user_id} in mode {mode}")

    system_prompt = build_system_prompt(mode)
    history = get_history(user_id)

    messages = [{"role": "system", "content": system_prompt}]

    # –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
    for h_role, h_text in history:
        messages.append({"role": h_role, "content": h_text})

    # –ù–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    messages.append({"role": "user", "content": user_message})

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ payload
    def build_payload(model_name):
        return {
            "model": model_name,
            "messages": messages,
            "max_tokens": 2048,
            "temperature": 0.4,
            "top_p": 0.95,
        }

    # ------------------------------------------------------------
    #  –ü–æ–ø—ã—Ç–∫–∞ ‚Ññ1 ‚Äî PRIMARY_MODEL
    # ------------------------------------------------------------
    models_to_try = [PRIMARY_MODEL] + FALLBACK_MODELS

    for model in models_to_try:
        try:
            payload = build_payload(model)
            response = await _send_request(payload)

            reply_text = response["choices"][0]["message"]["content"]

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            save_message(user_id, "user", user_message)
            save_message(user_id, "assistant", reply_text)

            return reply_text

        except Exception as e:
            logger.error(f"Model {model} failed: {e}")
            continue

    return "‚ùå –û—à–∏–±–∫–∞: –Ω–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å Groq –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


# ------------------------------------------------------------
#  –≠–∫—Å–ø–æ—Ä—Ç –Ω–∞—Ä—É–∂—É
# ------------------------------------------------------------
__all__ = [
    "ask_ai",
    "ask_vision",
    "ask_image_generation"
]
